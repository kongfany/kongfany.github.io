<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>联邦学习路线 - 乐观积极的...</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="kong" /><meta name="description" content="https://www.zhihu.com/question/422320791/answer/1805628004 Communication-Efficient Learning of Deep Networks from Decentralized Data 开山之作，FedAvg。 三个概念：Epoch, Batch, Iteration 参考2 epoch:一个Epoch就是将所有训练样本训练一次的过程 batc" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.87.0 with theme even" />


<link rel="canonical" href="https://kongfany.github.io/post/fl_route/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.b5a744db6de49a86cadafb3b70f555ab443f83c307a483402259e94726b045ff.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="联邦学习路线" />
<meta property="og:description" content="https://www.zhihu.com/question/422320791/answer/1805628004 Communication-Efficient Learning of Deep Networks from Decentralized Data 开山之作，FedAvg。 三个概念：Epoch, Batch, Iteration 参考2 epoch:一个Epoch就是将所有训练样本训练一次的过程 batc" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kongfany.github.io/post/fl_route/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-03-17T13:00:04+08:00" />
<meta property="article:modified_time" content="2022-03-17T13:00:04+08:00" />

<meta itemprop="name" content="联邦学习路线">
<meta itemprop="description" content="https://www.zhihu.com/question/422320791/answer/1805628004 Communication-Efficient Learning of Deep Networks from Decentralized Data 开山之作，FedAvg。 三个概念：Epoch, Batch, Iteration 参考2 epoch:一个Epoch就是将所有训练样本训练一次的过程 batc"><meta itemprop="datePublished" content="2022-03-17T13:00:04+08:00" />
<meta itemprop="dateModified" content="2022-03-17T13:00:04+08:00" />
<meta itemprop="wordCount" content="4926">
<meta itemprop="keywords" content="Federated Learning," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="联邦学习路线"/>
<meta name="twitter:description" content="https://www.zhihu.com/question/422320791/answer/1805628004 Communication-Efficient Learning of Deep Networks from Decentralized Data 开山之作，FedAvg。 三个概念：Epoch, Batch, Iteration 参考2 epoch:一个Epoch就是将所有训练样本训练一次的过程 batc"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">乐观积极的...</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">乐观积极的...</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">联邦学习路线</h1>

      <div class="post-meta">
        <span class="post-time"> 2022-03-17 </span>
        
          <span class="more-meta"> 4926 words </span>
          <span class="more-meta"> 10 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#英文论文整理">英文论文整理</a></li>
        <li><a href="#中文论文整理">中文论文整理：</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <blockquote>
<p><a href="https://www.zhihu.com/question/422320791/answer/1805628004">https://www.zhihu.com/question/422320791/answer/1805628004</a></p>
</blockquote>
<ul>
<li>
<p>Communication-Efficient Learning of Deep Networks from Decentralized Data</p>
<p>开山之作，FedAvg。</p>
</li>
</ul>
<blockquote>
<p><a href="https://www.jianshu.com/p/22c50ded4cf7?from=groupmessage">三个概念：Epoch, Batch, Iteration</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/66021413?utm_campaign=shareopn&amp;utm_medium=social&amp;utm_oi=1188913128606576640&amp;utm_psn=1552348883346403328&amp;utm_source=wechat_session">参考2</a></p>
</blockquote>
<ul>
<li>epoch:一个Epoch就是<strong>将所有训练样本训练一次</strong>的过程</li>
<li>batch:当一个Epoch的样本（也就是所有的训练样本）数量可能太过庞大（对于计算机而言），就需要把它分成多个小块，也就是就是分成多个Batch 来进行训练。将整个训练样本分成若干个Batch。</li>
</ul>
<h2 id="英文论文整理">英文论文整理</h2>
<ul>
<li>
<p><code>Trading Redundancy for Communication: Speeding up Distributed SGD for Non-convex Optimization</code>为通信交换冗余：加速非凸优化的分布式SGD</p>
<p><a href="http://proceedings.mlr.press/v97/haddadpour19a.html">paper</a>，<a href="https://github.com/mmkamani7/RI-SGD">code</a></p>
<p>已经有大量研究通过压缩梯度向量或使用局部更新和周期模型平均来降低通信成本。在本文中，我们提倡使用冗余实现非凸优化的通信高效分布式随机算法。通过适当地将冗余注入到具有模型平均的训练数据中，可以显著减少通信循环的数量。我们表明冗余减少了局部平均中的残余误差，从而与以前的算法相比，通过更少的通信循环达到相同的精度水平。</p>
<p>第3节中介绍了冗余注入SGD（RI-SGD）算法，它是分布式SGD的一种变体。在RI-SGD中，数据被划分为碎片；每个节点都有自己的数据碎片，并允许部分访问其他工作人员子集的碎片，达到强制冗余预算的水平（通过数据复制显式地或通过从其他工作人员的碎片中采样数据隐式地）。RI-SGD通过执行局部更新并周期性地平均节点上的模型来运行。</p>
<p>分布式SGD的周期模型平均技术中使用数据冗余。通过理论收敛性证明，我们表明，与没有冗余的传统算法相比，冗余减少了残余误差。通过实验结果，我们表明，冗余度非常值得隐含的较高计算成本。残余误差减少导致较低的通信开销，因此更快的收敛。</p>
</li>
<li>
<p>python main.py &ndash;data-dir=./cifar10  &ndash;num-gpus=8  &ndash;train-steps=45000 &ndash;variable-strategy GPU &ndash;job-dir=./log/ri-sgd/cifar10-ri-redun25-step50 &ndash;run-type multi  &ndash;redundancy=0.25   &ndash;sync-step=50  &ndash;dataset cifar10  &ndash;eval-batch-size=128</p>
<p>python main.py &ndash;data-dir=./cifar10 &ndash;num-gpus=8  &ndash;train-steps=45000 &ndash;variable-strategy GPU  &ndash;job-dir=./log/ri-sgd/cifar10-ri-sync  &ndash;run-type sync  &ndash;redundancy=0.0  &ndash;dataset cifar10 &ndash;eval-batch-size=128</p>
<p><code>ImageNet data set loader</code>.</p>
<p>2022-09-11 14:35:14.906706: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2022-09-11 14:35:14.907062: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback">INFO:tensorflow:Using config: {&#39;_model_dir&#39;: &#39;./log/ri-sgd/cifar10-ri-redun25-step50&#39;, &#39;_tf_random_seed&#39;: None, &#39;_save_summary_steps&#39;: 100, &#39;                  _save_checkpoints_steps&#39;: None, &#39;_save_checkpoints_secs&#39;: 600, &#39;_session_config&#39;: gpu_options {
  force_gpu_compatible: true
}
allow_soft_placement: true
, &#39;_keep_checkpoint_max&#39;: 5, &#39;_keep_checkpoint_every_n_hours&#39;: 10000, &#39;_log_step_count_steps&#39;: 100, &#39;_train_distribute&#39;: None, &#39;_device_fn&#39;:                   None, &#39;_protocol&#39;: None, &#39;_eval_distribute&#39;: None, &#39;_experimental_distribute&#39;: None, &#39;_experimental_max_worker_delay_secs&#39;: None, &#39;_service&#39;:                   None, &#39;_cluster_spec&#39;: &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7c0875d3c8&gt;, &#39;_task_type&#39;: &#39;worker&#39;, &#39;_task_id&#39;: 0,                   &#39;_global_id_in_cluster&#39;: 0, &#39;_master&#39;: &#39;&#39;, &#39;_evaluation_master&#39;: &#39;&#39;, &#39;_is_chief&#39;: True, &#39;_num_ps_replicas&#39;: 0, &#39;_num_worker_replicas&#39;: 1}
INFO:tensorflow:Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on R                  unConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.


INFO:tensorflow:Calling model_fn.
INFO:tensorflow:image after unit resnet_0/tower_0/stage/residual_v1/: (?, 16, 32, 32)
INFO:tensorflow:image after unit resnet_0/tower_0/stage/residual_v1_1/: (?, 16, 32, 32)
INFO:tensorflow:image after unit resnet_0/tower_0/stage/residual_v1_2/: (?, 16, 32, 32)
INFO:tensorflow:image after unit resnet_0/tower_0/stage/residual_v1_3/: (?, 16, 32, 32)
INFO:tensorflow:image after unit resnet_0/tower_0/stage/residual_v1_4/: (?, 16, 32, 32)
INFO:tensorflow:image after unit resnet_0/tower_0/stage/residual_v1_5/: (?, 16, 32, 32)
INFO:tensorflow:image after unit resnet_0/tower_0/stage/residual_v1_6/: (?, 16, 32, 32)
INFO:tensorflow:image after unit resnet_0/tower_0/stage/residual_v1_7/: (?, 16, 32, 32)


INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1/avg_pool/: (?, 16, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1/: (?, 32, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1_1/: (?, 32, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1_2/: (?, 32, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1_3/: (?, 32, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1_4/: (?, 32, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1_5/: (?, 32, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1_6/: (?, 32, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_1/residual_v1_7/: (?, 32, 16, 16)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1/avg_pool/: (?, 32, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1/: (?, 64, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1_1/: (?, 64, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1_2/: (?, 64, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1_3/: (?, 64, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1_4/: (?, 64, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1_5/: (?, 64, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1_6/: (?, 64, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/stage_2/residual_v1_7/: (?, 64, 8, 8)
INFO:tensorflow:image after unit resnet_0/tower_0/global_avg_pool/: (?, 64)
INFO:tensorflow:image after unit resnet_0/tower_0/fully_connected/: (?, 11)
....
INFO:tensorflow:image after unit resnet_7/tower_7/fully_connected/: (?, 11)


INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.


INFO:tensorflow:Restoring parameters from ./log/ri-sgd/cifar10-ri-redun25-step50/model.ckpt-0

INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2022-09-12-11:31:19
INFO:tensorflow:Saving dict for global step 15968: accuracy = 0.6301465, global_step = 15968, loss = 1.5022674
INFO:tensorflow:Saving &#39;checkpoint_path&#39; summary for global step 15968: ./log/ri-sgd/cifar10-ri-redun25-step50/model.ckpt-15968
INFO:tensorflow:Average examples/sec: 8519.77 (36.1553), step = 15968
INFO:tensorflow:Average examples/sec: 8522.79 (13192.8), step = 15984
INFO:tensorflow:loss = 1.036586, step = 16000 (194.717 sec)
INFO:tensorflow:learning_rate = 0.1, loss = 1.036586 (194.717 sec)
INFO:tensorflow:Average examples/sec: 8526.14 (14038.3), step = 16000
INFO:tensorflow:Parameters sync in progress for step: 16016
INFO:tensorflow:global_step/sec: 0.648187
INFO:tensorflow:Average examples/sec: 8528.51 (11820.3), step = 16016
INFO:tensorflow:Average examples/sec: 8532.07 (14665.4), step = 16032
INFO:tensorflow:Average examples/sec: 8535.52 (14336.2), step = 16048
INFO:tensorflow:Average examples/sec: 8539.39 (15664.3), step = 16064
INFO:tensorflow:Parameters sync in progress for step: 16072
INFO:tensorflow:Average examples/sec: 8541.96 (12247.8), step = 16080
INFO:tensorflow:Average examples/sec: 8545.82 (15637.8), step = 16096
INFO:tensorflow:Average examples/sec: 8549.6 (15410.1), step = 16112
INFO:tensorflow:Parameters sync in progress for step: 16128

INFO:tensorflow:global_step/sec: 36.6612
INFO:tensorflow:loss = 0.40698615, step = 44800 (21.542 sec)
INFO:tensorflow:learning_rate = 0.01, loss = 0.40698615 (21.542 sec)
INFO:tensorflow:Average examples/sec: 11149.1 (12165.7), step = 44800
INFO:tensorflow:Average examples/sec: 11150.1 (15085.6), step = 44816
INFO:tensorflow:Average examples/sec: 11151.3 (15706.3), step = 44832
INFO:tensorflow:Average examples/sec: 11152.5 (15819.3), step = 44848
INFO:tensorflow:Parameters sync in progress for step: 44856
INFO:tensorflow:Average examples/sec: 11152.9 (12614.2), step = 44864
INFO:tensorflow:Average examples/sec: 11154.1 (15997), step = 44880
INFO:tensorflow:Average examples/sec: 11155.3 (15720.3), step = 44896
INFO:tensorflow:Parameters sync in progress for step: 44912
INFO:tensorflow:global_step/sec: 38.2743
INFO:tensorflow:Average examples/sec: 11155.8 (12877), step = 44912
INFO:tensorflow:Average examples/sec: 11156.8 (14990.5), step = 44928
INFO:tensorflow:Average examples/sec: 11157.8 (14665.5), step = 44944
INFO:tensorflow:Average examples/sec: 11158.9 (15379), step = 44960
INFO:tensorflow:Parameters sync in progress for step: 44968
INFO:tensorflow:Average examples/sec: 11159.4 (12940.7), step = 44976
INFO:tensorflow:Average examples/sec: 11160.6 (15711.6), step = 44992


INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2022-09-12-11:48:01
INFO:tensorflow:Saving dict for global step 45008: accuracy = 0.88703126, global_step = 45008, loss = 0.6188442
INFO:tensorflow:Saving &#39;checkpoint_path&#39; summary for global step 45008: ./log/ri-sgd/cifar10-ri-redun25-step50/model.ckpt-45008
INFO:tensorflow:Loss for final step: 0.35805476.

</code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><code>Local SGD with Periodic Averaging: Tighter Analysis and Adaptive Synchronization</code>具有周期平均的局部SGD：更严格的分析和自适应同步</p>
<p><a href="https://arxiv.org/abs/1910.13598">paper</a>,<a href="https://github.com/mmkamani7/LUPA-SGD?utm_source=catalyzex.com">code</a></p>
<p>我们加强了局部SGD的收敛性分析，并表明局部SGD比当前理论所建议的成本低得多，应用范围也广得多。还开发了一种自适应同步方案，为线性加速提供了一般条件。</p>
<p>我们加强了分布式非凸优化的周期平均局部更新理论。我们改进了先前已知的局部更新次数的界限，同时保持了线性速度，并通过实验验证了我们的结果。我们还提出了一种自适应算法来决定算法进行时的局部更新次数。</p>
</li>
<li>
<p>Distributionally Robust Federated Averaging</p>
<p>我们通过<code>自适应</code>采样的周期性平均来研究用于分布式鲁棒联邦学习的通信高效分布式算法。</p>
<p>提出了一种分布式鲁棒联合平均 (DRFA) 算法，该算法采用一种新颖的快照方案来近似混合参数的历史梯度的累积。我们分析了 DRFA 在凸线性和非凸线性设置中的收敛速度。我们还将提出的想法推广到对混合参数进行正则化的目标，并提出了一种近端变体，称为 DRFA-Prox，具有可证明的收敛速度。我们还分析了在强凸-强-凹和非凸（在 PL 条件下）-强-凹设置中的正则化情况的替代优化方法。</p>
<p>提出的 DRFA 算法是第一个以通信有效的方式解决联邦学习的分布式鲁棒优化问题，并对异构（非 IID）数据分布进行理论分析。提出的将 w 的更新与 λ 解耦的想法可以作为构建块集成到其他联合优化方法</p>
<p>&ndash;</p>
<p>Federated Class-Incremental Learning</p>
<p>Global-Local Forgetting Compensation (GLFC) model, to learn a global class incremental model for alleviating the catastrophic forgetting from both local and global perspectives. 全局-局部遗忘补偿（GLFC）模型，从局部和全局的角度学习一个全局类增量模型来缓解灾难性的遗忘问题。</p>
<p>链接：</p>
<p><a href="http://arxiv.org/abs/2203.11473">http://arxiv.org/abs/2203.11473</a> 作者：OpenMPC开放隐私计算 <a href="https://www.bilibili.com/read/cv18409025">https://www.bilibili.com/read/cv18409025</a> 出处：bilibili</p>
</li>
</ul>
<h2 id="中文论文整理">中文论文整理：</h2>
<ul>
<li>
<p><code>面向隐私保护联邦学习的医学影像目标检测算法</code></p>
<p>服务器的时刻计算（MA）计算隐私损失，若超过阈值则意味着隐私预算已经消耗殆尽，则停止训练，返回当前轮参数。</p>
<p>为防止来自不可靠第三方的攻击, 服务器在更新全局模型参数时, 引入高斯噪声对其进行差分隐私保护. 在服务器聚合客户端局部模型的参数更新时 引入高斯噪声, 实现对全局模型参数的保护, 攻击 者即使访问到扰动后的参数也无法直接获取各客 户端的参与度和对模型的贡献, 因此可实现对全 部客户端私有数据的保护.</p>
<p>本文选择使用 RetinaNet 检测器进行 CT 影像综合性病灶检测。可以通过特征金字塔结构( FPN)结合不同语义级别的特征图来进行多尺度的目标检测,其低层特征图具有较高分辨率, 但特征呈现出低语义级别的特点; 而高层特征图的分辨率虽然较低, 但其特征包含的语义信息丰富.特别地, 本文借助上下文信息来提取自适应特征, 并引入注意力机制合理 利用不同分辨率的特征图, 通过这 2 个方面的改进 有效地提高了 RetinaNet 检测器的病灶检测精度.</p>
<p><code>RetinaNet </code>:[<a href="https://blog.csdn.net/weixin_41981679/article/details/123823507">1</a>],[<a href="https://blog.csdn.net/weixin_54546190/article/details/123558365">2</a>],[<a href="https://zhuanlan.zhihu.com/p/410436667">3</a>],[<a href="https://zhuanlan.zhihu.com/p/143877125">4</a>]</p>
<p>在客户端为折中考虑通信效率与隐 私保护, 从 2 个方面采取措施, 一是按照自适应的 训练周期进行训练以加速模型收敛; 二是在其局 部目标函数中加入限制项, 以防止局部模型和全 局模型之间产生巨大偏差, 保证收敛.</p>
<p>因数据量有限, 在完成对客户端 的初始数据分配后, 对其私有数据进行数据增强操 作, 将分配后的数据集以 6∶2∶2 的比例划分为训 练集、验证集和测试集. 本文采用翻转、平移、旋 转、仿射和裁剪等数据增强方式对各客户端数据进 行扩充, 令各类型数据扩充为原来的 5 倍.</p>
<p>联邦平均算法 FedAvg[1]是一种基于局部随机梯度下降平均更新 的方法, 在非凸问题上表现良好, 但没有收敛性保 证. 基于 FedAvg 改进的 FedProx 方法[14]则提供了 理论和实践上的收敛性保证. 在现有的机器学习 方法中, 局部更新的方式得到了广泛应用. 除了灵 活的局部更新策略外, 采用自适应的局部训练周 期可以实现快速收敛, 并降低损失[15].本文一方面在客户端的目标函数中加 入了限制项防止局部模型和全局模型差异过大,  从而保证收敛性; 另一方面采用自适应训练周期 和局部更新的思想提升模型的收敛速度. 实验结 果表明, 该方式在保证收敛性的前提下, 提高了模 型的收敛速度, 并整体提升了通信效率.</p>
</li>
<li>
<p><code>基于联邦学习和改进 ResNet 的肺炎辅助诊断</code></p>
<p>本文方法利用改进残差网络能提取更深层次的图像特征, 嵌入压缩激励模块关注通道特征, 并进行特征重标定增强有效特征的提取, 能够提高联邦共享模型的准确性, 同时本文方法具有本地数据不对外共享的优势, 能够有效保护医疗数据的隐私, 从而打破医疗数据孤岛现象。</p>
<p>为了提取更深层次的特征同时避免梯度消失, 本文以残差网络作为基础模型, 在联邦学习过程中, 各个客户端在本地进行独立训练, 为了避免批处理数量对于联邦共享模型的影响, 本文将传统的批量归一化方式转换为<code>组归一</code>化方式, 对输入特征的通道进行分组运算,提高了模型的稳定性, 同时引入激励压缩网络关注通道间的相关性.</p>
<p>BN,GN:<a href="https://www.cnblogs.com/dengshunge/p/12513712.html">1</a></p>
</li>
<li>
<p><code>一种 Unet 图像分割模型的联邦蒸馏优化算法 </code></p>
<p>在算法中，首先设计本地教师模型-全局学生模型的框架，重构轻量的Unet 作为学生模型，并用蒸馏损失保证模型性能的稳定。然后，在服务器上部署调节器筛选聚合的参与方，缓解数据不平衡对模型的影响</p>
<p>首先在联邦平均算法（Federated Averaging，FedAvg）的基础上使用教师-学生模型，其中在参与方中有一个经典的 Unet 模型作为教师模型，还有一个轻量的 U-net 模型结构作为学生模型，通过教师-学生的框架保证本地参与方性能的稳定；然后本文在服务器上还部署调节器，并设定设置相关的约束条件与权重设置机制。</p>
<p>本次设计的 U-FedDO 算法主要有服务器、调节器、参与方的学生模型与参与方的教师模型。服务器负责全局权重
的聚合与输出给本地模型，调节器是本地传递的权重进行筛选，参与方中有教师模型保留本地模型的权重，学生模型主要负责训练服务器传递的权重与结合本地教师模型的损失。</p>
</li>
<li>
<p>经实践表明FedAvg 有很好的表现, 特别是对于求解非凸问题, 它的效果很好, 但是 McMahan 等人在提出这一算法的时候没有给出 FedAvg 算法在理论上的收敛性保证, 并且他们是在数据独立同分布 (IID) 的情况下进行的研究. 不过目前对于 FedAvg 算法的收敛性, Huo 等人在 [9] 中已给出理论性的证明, 另外, 他们还提出了一种带动量加速的 FedAvg 算法, 并说明该算法在数值上较之先前的 FedAvg 有更快的收敛速度.</p>
<p>数据异质性会影响算法的收敛性.Li 等人在 [25] 中基于基本的 FedAvg 算法考虑异质性, 提出了一个叫做 FedProx 的算法,该算法在 FedAvg 的基础上对每个设备的局部目标函数添加了一项邻近项以控制本地更新的模型与全局模型的偏离程度. 他们证明了在目标函数为非凸情况下的 FedProx 的收敛性, 并通过实验表明了<code>FedProx</code>在处理异质数据时训练的模型精度更高</p>
<p>提取图像特征, 然后将这些图像特征输入分类器. 最后, 分类器输出这些图像的识别结果.</p>
<p>针对联邦学习中通信效率以及数据异质性上的问题, 本文提出了一种带压缩及梯度追踪的方差缩减的联邦优化算法框架, 称作 FedCOMGATE-VR. 该算法一方面为了提高通信效率, 降低通信成本, 使用了本地更新与压缩梯度两种思想; 另一方面, 为了处理数据异质性的问题, 算法中还引入了一种梯度追踪的思想. 此外, 算法在局部梯度
更新中还采用了方差缩减且无偏的随机梯度法, 以减少每次梯度更新的计算量.</p>
<p>FedCOM 的每次更新都严重依靠于局部的 SGD 方向, 在同质的情况下, 由于所有的数据的分布都是一致的, 按局部梯度方向走能够很好地训练出一个全局模型, 但是在异质的情况下, 如果仅仅依靠于局部的梯度来更新局部的模型会导致局部梯度方向与全局梯度方向产生很大的差异.</p>
<p>FedCOMGATE使用了一种局部梯度追踪的思想, 该思想保证了每个节点都能用全局的梯度方向来更新局部的模型. 具体实现就是利用每次记录的局部梯度方向与全局梯度方向之间的差异来矫正每次局部模型更新.在算法的本地更新阶段使用的是 SGD 的随机梯度下降法. SGD 的操作虽较为简单, 但是它由于常数方差上界的干扰, 收敛效果不太理想, 因此本文考虑使用<code>方差缩减的随机梯度估计法</code>来进行局部梯度的更新..FedCOMGATE-VR</p>
<p>对于优化算法的效果分析, 一个很重要的指标就是观察它的收敛率情况. 损失值下降越快表示算法收敛越快.在分类效果的评价指标选择上, 我们选择了准确率 (Accuracy)、精确率 (Precision)、召回率 (Recall) 和 FI 值这四个指标</p>
<p>对于数据异质的情况, 为了生成类似于真实的联邦学习背景下的异质性数据, 我们采取和 [8] 中类似的方法: 每个设备仅被分配有来自两个类别的数据, 这一数据分配方法使得各个设备上的数据具有高度异质性.</p>
</li>
</ul>
<blockquote>
<p><a href="https://baijiahao.baidu.com/s?id=1731530035463540612&amp;wfr=spider&amp;for=pc">常用插件</a></p>
<ul>
<li>CatalyzeX</li>
<li>CCFrank</li>
</ul>
<p>Chrome 扩展程序、Firefox 和 Edge 附加组件，在 dblp、Google 学术、Connected Papers、Semantic Scholar 和 Web of Science 的搜索结果中显示中国计算机学会推荐的国际会议和期刊排名。</p>
</blockquote>
<hr>
<blockquote>
<p>联邦学习书籍</p>
<p><a href="https://www.zhihu.com/column/c_1392436990781046784">深入浅出</a></p>
</blockquote>
<hr>
<blockquote>
<p>论文查询</p>
<p><a href="https://ai-paper-collector.vercel.app/">https://ai-paper-collector.vercel.app/</a></p>
<p><a href="https://dblp.uni-trier.de/">https://dblp.uni-trier.de/</a></p>
<p><a href="https://youngfish42.github.io/Awesome-Federated-Learning-on-Graph-and-Tabular-Data/">https://youngfish42.github.io/Awesome-Federated-Learning-on-Graph-and-Tabular-Data/</a></p>
</blockquote>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">kong</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2022-03-17
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/federated-learning/">Federated Learning</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/fl_fedavg/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">FedAvg</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/deep-learning/">
            <span class="next-text nav-default">深度学习入门-基于python</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=_JOXlp_emZaBjZ3IwcrMuImJ1puXlQ" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/kongfany" class="iconfont icon-github" title="github"></a>
      <a href="https://weibo.com/u/5947688533?is_all=1" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://www.zhihu.com/people/yu-ni-zhong-nian-bu-yu" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://space.bilibili.com/232669848" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://kongfany.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2023<span class="heart"><i class="iconfont icon-heart"></i></span><span>kong</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script type="text/javascript" async src="/lib/mathjax/es5/tex-mml-chtml.js"></script>








</body>
</html>
