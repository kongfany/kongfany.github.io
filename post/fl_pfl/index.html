<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>PFL联邦学习开源框架 - 大胖狗来了</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="kong" /><meta name="description" content="PFL联邦学习框架是基于pytorch开发的集成了多种联邦学习算法的联邦学习框架。 使用PFL框架可以通过简单的代码编写，和参数设置来完成一个" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.87.0 with theme even" />


<link rel="canonical" href="https://kongfany.github.io/post/fl_pfl/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.b5a744db6de49a86cadafb3b70f555ab443f83c307a483402259e94726b045ff.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="PFL联邦学习开源框架" />
<meta property="og:description" content="PFL联邦学习框架是基于pytorch开发的集成了多种联邦学习算法的联邦学习框架。 使用PFL框架可以通过简单的代码编写，和参数设置来完成一个" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kongfany.github.io/post/fl_pfl/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-12-17T21:05:53+08:00" />
<meta property="article:modified_time" content="2021-12-17T21:05:53+08:00" />

<meta itemprop="name" content="PFL联邦学习开源框架">
<meta itemprop="description" content="PFL联邦学习框架是基于pytorch开发的集成了多种联邦学习算法的联邦学习框架。 使用PFL框架可以通过简单的代码编写，和参数设置来完成一个"><meta itemprop="datePublished" content="2021-12-17T21:05:53+08:00" />
<meta itemprop="dateModified" content="2021-12-17T21:05:53+08:00" />
<meta itemprop="wordCount" content="5096">
<meta itemprop="keywords" content="Federated Learning," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="PFL联邦学习开源框架"/>
<meta name="twitter:description" content="PFL联邦学习框架是基于pytorch开发的集成了多种联邦学习算法的联邦学习框架。 使用PFL框架可以通过简单的代码编写，和参数设置来完成一个"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">大胖狗来了</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">大胖狗来了</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">PFL联邦学习开源框架</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-12-17 </span>
        
          <span class="more-meta"> 5096 words </span>
          <span class="more-meta"> 11 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#pfl框架优势">PFL框架优势</a></li>
        <li><a href="#pfl框架设计">PFL框架设计</a></li>
        <li><a href="#演示">演示</a>
          <ul>
            <li><a href="#pfl_modelpy"><code>pfl_model.py</code></a></li>
            <li><a href="#pfl_serverpy"><code>pfl_server.py</code></a></li>
            <li><a href="#pfl_clientpy"><code>pfl_client.py</code></a></li>
            <li><a href="#流程分析">流程分析</a></li>
          </ul>
        </li>
        <li><a href="#gfl">GFL</a>
          <ul>
            <li><a href="#abstract">Abstract：</a></li>
            <li><a href="#introduction">Introduction：</a></li>
            <li><a href="#contributions">contributions</a></li>
            <li><a href="#related-work">Related Work</a></li>
            <li><a href="#the-proposed-framework">The Proposed Framework</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>PFL联邦学习框架是基于pytorch开发的集成了多种联邦学习算法的联邦学习框架。</p>
<p>使用PFL框架可以通过简单的代码编写，和参数设置来完成一个联邦学习模型训练任务。</p>
<h2 id="pfl框架优势">PFL框架优势</h2>
<ul>
<li>PFL目前集成了传统的FedAvg联邦学习算法和基于知识蒸馏的联邦学习算法。</li>
<li>即将提供基于区块链的通信支持，结合知识蒸馏的联邦学习算法，为用户提供去中心化的联邦学习服务</li>
</ul>
<h2 id="pfl框架设计">PFL框架设计</h2>
<p><img src="/images/202112/20.png" alt=""></p>
<p>在prepare_job阶段，模型方需要制定各种策略，设计好联邦学习任务。在run_time阶段，使用模型方生成的job协调fl_client客户端和fl_server服务端进行联邦学习训练。如图，PFL框架支持多对多的server和client通信模式。</p>
<p>prepare job：模型方准备联邦学习任务阶段</p>
<ul>
<li>FederateSrategy:联邦学习算法策略选择，目前提供FED_AVG和FED_DISTILLATION两种选项</li>
<li>WorkModeStrategy:工作模式选择，目前可以选择单机模式和集群模式</li>
<li>TrainStrategy:训练策略，定义联邦学习任务的迭代次数</li>
<li>User-Defined-Model:定义好一个运行需要的模型类，用户自定义的模型类</li>
</ul>
<p>FL Run-Time:使用模型方生成的job协调FLClient客户端和FLServer服务端进行联邦学习训练</p>
<ul>
<li>FLClient:根据FederateStrategy来执行客户端对应的操作</li>
<li>FLServer:根据FederateStrategy来执行不同的启动策略</li>
</ul>
<h2 id="演示">演示</h2>
<p>使用单例模式进行演示</p>
<p>服务端的pfl_model,pfl_server</p>
<p>和客户端的pfl_client</p>
<h3 id="pfl_modelpy"><code>pfl_model.py</code></h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># pfl_model:模型文件，定义训练时使用的模型，并且生成相应的联邦学习任务</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="c1"># pfl的核心策略包，包含pfl的工作模式策略，联邦学习算法策略和训练策略</span>
<span class="kn">import</span> <span class="nn">gfl.core.strategy</span> <span class="k">as</span> <span class="nn">strategy</span>
<span class="c1"># pfl的任务管理包</span>
<span class="kn">from</span> <span class="nn">gfl.core.job_manager</span> <span class="kn">import</span> <span class="n">JobManager</span>


<span class="c1"># 定义了一个简单的模型类net</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
    <span class="c1"># 实例化模型model，和任务管理器job_manager</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
    <span class="n">job_manager</span> <span class="o">=</span> <span class="n">JobManager</span><span class="p">()</span>
    <span class="c1"># 定义一个联邦学习任务job，工作模式设为单例模式，（也可以使用集群模式），联邦学习算法策略为联邦平均法，（也可以使用联邦蒸馏算法），epoch为3，模型类型为net</span>
    <span class="n">job</span> <span class="o">=</span> <span class="n">job_manager</span><span class="o">.</span><span class="n">generate_job</span><span class="p">(</span><span class="n">work_mode</span><span class="o">=</span><span class="n">strategy</span><span class="o">.</span><span class="n">WorkModeStrategy</span><span class="o">.</span><span class="n">WORKMODE_STANDALONE</span><span class="p">,</span>
                                   <span class="n">fed_strategy</span><span class="o">=</span><span class="n">strategy</span><span class="o">.</span><span class="n">FederateStrategy</span><span class="o">.</span><span class="n">FED_AVG</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">Net</span><span class="p">)</span>
    <span class="c1"># 向job_manager传入定义好的job和model</span>
    <span class="n">job_manager</span><span class="o">.</span><span class="n">submit_job</span><span class="p">(</span><span class="n">job</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

</code></pre></td></tr></table>
</div>
</div><h3 id="pfl_serverpy"><code>pfl_server.py</code></h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="c1"># 根据在pfl_model文件中设置的job参数</span>
<span class="c1"># 从server包中导入了FLStandaloneServer，再从strategy中导入的联邦学习策略算法FederateStrategy</span>
<span class="kn">from</span> <span class="nn">gfl.core.server</span> <span class="kn">import</span> <span class="n">FLStandaloneServer</span>
<span class="kn">from</span> <span class="nn">gfl.core.strategy</span> <span class="kn">import</span> <span class="n">FederateStrategy</span>

<span class="n">FEDERATE_STRATEGY</span> <span class="o">=</span> <span class="n">FederateStrategy</span><span class="o">.</span><span class="n">FED_AVG</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
    <span class="c1"># 定义好server的联邦学习方法策略为FederateStrategy,并启动server</span>
    <span class="n">FLStandaloneServer</span><span class="p">(</span><span class="n">FEDERATE_STRATEGY</span><span class="p">)</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

<span class="c1"># 运行后日志提示聚合开始</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="pfl_clientpy"><code>pfl_client.py</code></h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="c1"># 导入pfl的相关包，包括客户端包，策略包，训练控制器</span>
<span class="kn">from</span> <span class="nn">gfl.core.client</span> <span class="kn">import</span> <span class="n">FLClient</span>
<span class="kn">from</span> <span class="nn">gfl.core.strategy</span> <span class="kn">import</span> <span class="n">WorkModeStrategy</span><span class="p">,</span> <span class="n">TrainStrategy</span><span class="p">,</span> <span class="n">LossStrategy</span>
<span class="kn">from</span> <span class="nn">gfl.core.trainer_controller</span> <span class="kn">import</span> <span class="n">TrainerController</span>

<span class="n">CLIENT_ID</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
    <span class="c1"># CLIENT_ID = int(sys.argv[1])</span>
    <span class="c1"># 数据集mnist的导入</span>
    <span class="n">mnist_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s2">&#34;D:\Python\PycharmProjects\pflttt\mnist_data&#34;</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.13066062</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.30810776</span><span class="p">,))</span>
    <span class="p">]))</span>
    <span class="c1"># 实例化一个客户端</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">FLClient</span><span class="p">()</span>
    <span class="c1"># 获得服务器端的模型pfl</span>
    <span class="n">gfl_models</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_remote_gfl_models</span><span class="p">()</span>

    <span class="c1"># 由于一个flclient可以参与多个job，所以获得的pflmodels也有可能是多个</span>
    <span class="c1"># 循环遍历这些模型</span>
    <span class="k">for</span> <span class="n">gfl_model</span> <span class="ow">in</span> <span class="n">gfl_models</span><span class="p">:</span>
        <span class="c1"># 对于每个模型，要定义好优化集，optimize，和训练策略，train_strategy</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">gfl_model</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">train_strategy</span> <span class="o">=</span> <span class="n">TrainStrategy</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">LossStrategy</span><span class="o">.</span><span class="n">NLL_LOSS</span><span class="p">)</span>
        <span class="c1"># 并将策略传入到对应的pfl_model中，(不同的模型也可以设置不同的训练策略)</span>
        <span class="n">gfl_model</span><span class="o">.</span><span class="n">set_train_strategy</span><span class="p">(</span><span class="n">train_strategy</span><span class="p">)</span>

    <span class="c1"># 调用TrainerController设置工作模式为单例模式，模型为pfl_models,数据为mnist数据集</span>
    <span class="c1"># 客户端id为0，curve设置本地是否显示训练曲线，concurrent_num为本地线程数</span>
    <span class="c1"># 启动TrainerController</span>
    <span class="n">TrainerController</span><span class="p">(</span><span class="n">work_mode</span><span class="o">=</span><span class="n">WorkModeStrategy</span><span class="o">.</span><span class="n">WORKMODE_STANDALONE</span><span class="p">,</span> <span class="n">models</span><span class="o">=</span><span class="n">gfl_models</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mnist_data</span><span class="p">,</span> <span class="n">client_id</span><span class="o">=</span><span class="n">CLIENT_ID</span><span class="p">,</span>
                      <span class="n">curve</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">concurrent_num</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="流程分析">流程分析</h3>
<p>运行pfl_model后可以看到，job已经生成并添加成功了。同时在日志文件中也有了相应的记录。
编写pfl_server以及pfl_client
先运行pfl_server，运行后日志提示聚合开始
然后运行pfl_client,可以看到client已经获取到了job，载入模型开始进行训练
等client完成一轮训练后，可以在server端看到第一轮的参数聚合在server端完成了。
训练完成后，会产生一个模型文件</p>
<p>当然pfl框架也可以使用集群模式进行训练
只需要在client和server文件中声明地址，并选择工作模式为集群模式即可
<a href="https://galaxylearning.github.io/quickstart/">https://galaxylearning.github.io/quickstart/</a></p>
<h2 id="gfl">GFL</h2>
<p>A Decentralized Federated Learning Framework Based On Blockchain</p>
<p>GFL:一个基于<code>区块链</code>的<code>去中心化</code>联邦学习框架</p>
<h3 id="abstract">Abstract：</h3>
<p>当前的FL框架在恶意节点攻击下如何提高通信性能、保持安全性和鲁棒性是一个巨大的挑战。本文提出了一种基于区块链的去中心化的FL学习框架——银河联邦学习框架(Galaxy  Federated Learning Framework, GFL)。GFL引入了<code>一致哈希算法</code>来提高通信性能，并提出了一种新的<code>环形去中心化</code>FL算法(RDFL)来提高分散FL性能和带宽利用率。此外，GFL还引入了星际文件系统(InterPlanetary File System, <code>IPFS</code>)和<code>区块链</code>，进一步提高了通信效率和FL的安全性。在恶意节点和非独立同分布（非IID）数据集的数据中毒情况下，提高通信性能和分散FL性能。</p>
<h3 id="introduction">Introduction：</h3>
<p>传统的FL框架使用中心化的体系结构，中心结点收集梯度或模型参数来更新全局模型。传统的压力和挑战：中心结点的通信压力和通信带宽瓶颈以及通信压力带来的中心结点的稳定性挑战。</p>
<p>提出了去中心化的FL框架：移除了中心结点，并在数据结点之间同步FL更新，然后执行聚合。在突破通信瓶颈和提高FL稳定性方面取得了一些进展，但是仍面临通信压力、分散FL性能和安全方面的挑战。用于同步FL更新的去中心化FL框架会造成更大的通信压力。由于数据节点中恶意节点的数据中毒以及非独立同分布（非IID）问题，现有去中心化FL框架中使用的聚合算法无法实现竞争性能。此外，现有去中心化FL框架的更新过程存在被篡改的安全风险，并且由于缺乏共识（协商一致）机制，无法追踪FL更新的来源。</p>
<p>为了解决上述问题，本文提出了一种基于区块链的去中心化FL框架——银河联邦学习框架（GFL）。GFL采用一致性哈希算法构建数据节点的环形拓扑，旨在降低通信压力，提高拓扑稳定性。此外，本文还设计了一种新颖的环形去中心化FL算法（RDFL）。在RDFL中引入了<code>RingAllReduce</code>算法和<code>知识蒸馏</code>，以提高带宽利用率和去中心化FL性能。此外，还引入了星际文件系统（IPFS）和区块链，以进一步提高分散FL的通信效率和安全性。</p>
<p><code>Consistent Hashing Algorithm:</code><a href="https://www.cnblogs.com/frankcui/p/15354596.html">一致性哈希算法</a>(<a href="https://www.cnblogs.com/xialihua1023/p/10304932.html">Consistent Hashing Algorithm</a>)。是一种分布式算法，常用于负载均衡。Memcached client也选择这种算法，解决将key-value均匀分配到众多cahce server上的问题。它可以取代传统的取模操作，解决了取模操作无法应对增删cached Server的问题 (增删server会导致同一个key,在get操作时分配不到数据真正存储的server，命中率会急剧下降)。简单来说，是将整个哈希值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织。将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置<strong>沿环顺时针“行走”</strong>，第一台遇到的服务器就是其应该定位到的服务器。</p>
<p><code>RingAllReduce:</code><a href="https://blog.csdn.net/lj2048/article/details/108322931">ring allreduce</a>是一种算法，其通信成本是恒定的并且与系统中GPU的数量无关，并且仅由系统中GPU之间的最慢连接确定; 事实上，如果你只考虑带宽作为通信成本的一个因素（并忽略延迟），那么ring allreduce是一种最佳的通信算法。（当您的模型很大时，这是对通信成本的一个很好的预估，并且您只需要较少数次数发送大量数据。）Ring allreduce中的GPU排列在一个逻辑环中。 每个GPU应该有一个左邻居和一个右邻居; 它只会向其右邻居发送数据，并从其左邻居接收数据。该算法分两步进行：第一步是scatter-reduce，然后是all-gather。 在scatter-reduce步骤中，GPU将交换数据，使得每个GPU最终得到最终结果的一部分。 在all-gather步骤中，GPU将交换这些块，以便所有GPU最终得到完整的最终结果。</p>
<p><code>IPFS:</code><a href="https://blog.csdn.net/CHYabc123456hh/article/details/105437637">IPFS</a>（InterPlanetary File System）叫星际文件传输系统，本质是一个基于点对点的分布式超媒体分发协议，它整合了分布式系统，为所有人提供全球统一的可寻址空间，因为他具有良好的安全性、较高的传输速度等特点，被认为是最有可能取代HTTP的新一代互联网协议。IPFS用基于内容的寻址替代传统的基于域名的寻址。用户不需要关心服务器的位置，不用考虑文件存储的名字和路径。我们将一个文件放到IPFS节点中，将会得到基于其内容计算出的唯一加密哈希值。哈希值直接反映文件的内容，哪怕只修改1比特，哈希值也会完全不同。当IPFS被请求一个文件哈希时，它会使用一个分布式哈希表找到文件所在的节点，取回文件并验证文件的哈希值，如果哈希值不符合，说明内容被篡改了。将传统的基于内容的地址替代基于域名的地址，也就是用户寻找的不是某个地址而是储存在某个地方的内容，不需要验证发送者的身份，而只需要验证内容的哈希，通过这样可以让网页的速度更快、更安全、更健壮、更持久。</p>
<p><code>Knowledge Distillation：</code><a href="https://baijiahao.baidu.com/s?id=1683133392734090972&amp;wfr=spider&amp;for=pc">知识蒸馏</a>,培养一个能很好表现和概括的大模型。这就是所谓的教师模式。取你所有的数据，计算教师模型的预测值。包含这些预测的总数据集称为知识，而预测本身通常称为软目标。这就是知识提炼的步骤。利用之前获得的知识来训练较小的网络，称为学生模型。</p>
<p><code>blockchain:</code><a href="http://blockchain.idcquan.com/162625.shtml">区块链</a>(<a href="https://baijiahao.baidu.com/s?id=1648712868414807289&amp;wfr=spider&amp;for=pc">Blockchain</a>)是分布式数据存储、点对点传输、共识机制、加密算法等计算机技术的新型应用模式。”所谓共识机制是区块链系统中实现不同节点之间建立信任、获取权益的数学算法。区块链就是一种网络技术，通过程序员敲代码形成的网络，各方相互合作交易均可直接对接完成，不需要靠第三方平台，也就省去了中间的一些程序和费用(省时省力还省钱)，但为了合作或交易的安全，系统会将每一个参与者的动作广播给所有参与者，保障了整个过程的安全、透明，解决了信任问题。区块链准确的说就是“全中心”体系，就是链上的每个节点都是中心。不可删除，不可更改，这就是区块链技术。</p>
<h3 id="contributions">contributions</h3>
<ul>
<li>设计了一种新的去中心化FL数据节点拓扑机制，采用了一致性哈希算法。该机制能够显著降低通信压力，提高拓扑稳定性。据我们所知，这是第一次尝试在去中心化FL框架中为数据节点拓扑设计引入一致性哈希算法。</li>
<li>提出了一种新的环分散联邦学习（RDFL）算法，旨在提高训练中的带宽利用率和分散联邦学习性能。</li>
<li>为了提高去中心化的FL框架的通信性能和安全性，我们引入IPFS技术来降低系统通信压力，并引入区块链来提高FL的安全性。</li>
</ul>
<h3 id="related-work">Related Work</h3>
<ul>
<li>
<p>中心化FL：存在通信瓶颈和稳定性问题</p>
</li>
<li>
<p>去中心化FL：基于八卦算法和模型分割的去中心化FL算法，点对点的去中心化FL算法，完全分散的FL算法，基于区块链的分散FL框架。在分散的FL性能和安全性方面面临挑战。</p>
</li>
<li>
<p>解决通信问题：主要集中在研究新的通信压缩或模型压缩技术来降低通信压力。利用八卦算法提高带宽利用率，并通过模型分割降低通信压力。降低沟通压力的模型量化方法。通信压缩方法，以降低通信压力。</p>
</li>
<li>
<p>提高Non-IID数据集上的FL性能：现有研究主要集中在集中式FL上，共享数据集，知识蒸馏。</p>
<p>在分散FL场景中，为了提高非IID数据集上的分散FL性能和恶意数据节点的数据中毒，Li提出了一个分散FL框架，但在没有数据中毒的情况下，没有实现比联邦平均（FedAvg）更好的性能。</p>
</li>
<li>
<p>保护数据隐私：现有的研究集中在新的防御方法上，如差分隐私和多方安全计算。也有研究将区块链技术应用于分散FL，以提高安全性。</p>
</li>
</ul>
<h3 id="the-proposed-framework">The Proposed Framework</h3>
<ul>
<li>描述了GFL中设计的拓扑机制如何利用一致性哈希算法为数据节点构建环形分散FL拓扑</li>
<li>在GFL中描述了RDFL算法</li>
<li>描述了GFL如何利用IPF和区块链来降低通信压力和提高FL安全性</li>
</ul>
<blockquote>
<p><a href="https://www.bilibili.com/video/BV12E411H7Lk?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click">视频</a></p>
<p><a href="https://github.com/GalaxyLearning/GFL">项目地址</a></p>
<p><a href="https://galaxylearning.github.io/">galaxylearning官方网站</a></p>
<p><a href="https://arxiv.org/abs/2010.10996">论文</a></p>
</blockquote>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">kong</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2021-12-17
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/federated-learning/">Federated Learning</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/fl_faq/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">联邦学习综述</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/%E5%9B%BE%E5%83%8F%E9%87%8D%E5%BB%BA/">
            <span class="next-text nav-default">3D人体重建</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=_JOXlp_emZaBjZ3IwcrMuImJ1puXlQ" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/kongfany" class="iconfont icon-github" title="github"></a>
      <a href="https://weibo.com/u/5947688533?is_all=1" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://www.zhihu.com/people/yu-ni-zhong-nian-bu-yu" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://space.bilibili.com/232669848" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://kongfany.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2021<span class="heart"><i class="iconfont icon-heart"></i></span><span>kong</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script type="text/javascript" async src="/lib/mathjax/es5/tex-mml-chtml.js"></script>








</body>
</html>
